{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-19T02:39:08.613983Z",
     "start_time": "2023-07-19T02:38:51.400929Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory train/. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m img_width \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m416\u001B[39m\n\u001B[1;32m      3\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m\n\u001B[0;32m----> 6\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_dataset_from_directory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mimg_height\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_width\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/image_dataset.py:299\u001B[0m, in \u001B[0;36mimage_dataset_from_directory\u001B[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001B[0m\n\u001B[1;32m    295\u001B[0m image_paths, labels \u001B[38;5;241m=\u001B[39m dataset_utils\u001B[38;5;241m.\u001B[39mget_training_or_validation_split(\n\u001B[1;32m    296\u001B[0m     image_paths, labels, validation_split, subset\n\u001B[1;32m    297\u001B[0m )\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m image_paths:\n\u001B[0;32m--> 299\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    300\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo images found in directory \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAllowed formats: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mALLOWLIST_FORMATS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    302\u001B[0m     )\n\u001B[1;32m    304\u001B[0m dataset \u001B[38;5;241m=\u001B[39m paths_and_labels_to_dataset(\n\u001B[1;32m    305\u001B[0m     image_paths\u001B[38;5;241m=\u001B[39mimage_paths,\n\u001B[1;32m    306\u001B[0m     image_size\u001B[38;5;241m=\u001B[39mimage_size,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    312\u001B[0m     crop_to_aspect_ratio\u001B[38;5;241m=\u001B[39mcrop_to_aspect_ratio,\n\u001B[1;32m    313\u001B[0m )\n\u001B[1;32m    314\u001B[0m dataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mprefetch(tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mAUTOTUNE)\n",
      "\u001B[0;31mValueError\u001B[0m: No images found in directory train/. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "img_height = 416\n",
    "img_width = 416\n",
    "batch_size = 32\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def load_annotations(json_file) -> List[Dict[str, any]]:\n",
    "    with open(json_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    return annotations\n",
    "\n",
    "def apply_transformations(image_dir, annotations_file):\n",
    "    annotations = load_annotations(annotations_file)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # rotate images by 10 degrees\n",
    "        width_shift_range=0.1,  # shift images horizontally by 10%\n",
    "        height_shift_range=0.1,  # shift images vertically by 10%\n",
    "        shear_range=0.2,  # shear transformations\n",
    "        zoom_range=0.2,  # zoom transformations\n",
    "        horizontal_flip=True,  # flip images horizontally\n",
    "        vertical_flip=False,  # do not flip images vertically\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "            image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image_array = tf.expand_dims(image_array, 0)  # Add batch dimension\n",
    "\n",
    "            augmented_images = datagen.flow(image_array, batch_size=1)\n",
    "\n",
    "            for i, augmented_image in enumerate(augmented_images):\n",
    "                augmented_image = augmented_image[0].astype('uint8')\n",
    "                new_filename = f\"transformed_{i}_{filename}\"\n",
    "                new_image_path = os.path.join(image_dir, new_filename)\n",
    "                tf.keras.preprocessing.image.save_img(new_image_path, augmented_image)\n",
    "\n",
    "                # Update annotations for the transformed image (optional)\n",
    "                # if filename in annotations[\"image\"]:\n",
    "\n",
    "                annotation = next(filter(lambda x: x[\"image\"] == filename, annotations), None)\n",
    "                if annotation is not None:\n",
    "                    # TODO figure out how to apply the same transformation to the bounding boxes\n",
    "                    pass\n",
    "\n",
    "                    # transformed_annotations = annotations[filename]\n",
    "\n",
    "                    # transformed_annotations['filename'] = new_filename\n",
    "                    # transformed_annotations_path = os.path.join(image_dir, f\"{new_filename}_annotations.createml.json\")\n",
    "                    # with open(transformed_annotations_path, 'w') as f:\n",
    "                    #     json.dump(transformed_annotations, f)\n",
    "\n",
    "                if i >= 9:  # Generate a maximum of 10 transformed images\n",
    "                    break\n",
    "\n",
    "# Usage example\n",
    "training_dir = './train'\n",
    "annotations_file = './train/_annotations.createml.json'\n",
    "apply_transformations(training_dir, annotations_file)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T03:02:23.423569Z",
     "start_time": "2023-07-19T03:02:23.386528Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
